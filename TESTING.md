# Testing Guide - H∆∞·ªõng d·∫´n Test M√¥ h√¨nh

## T·ªïng quan

D·ª± √°n cung c·∫•p h·ªá th·ªëng test to√†n di·ªán ƒë·ªÉ ƒë√°nh gi√° m√¥ h√¨nh sau khi training, bao g·ªìm:

1. **Comprehensive Model Testing** (`test_model.py`) - Test t·ªïng th·ªÉ v·ªõi metrics v√† visualizations
2. **Unit Tests** (`tests/`) - Test c√°c th√†nh ph·∫ßn ri√™ng l·∫ª
3. **Evaluation Script** (`evaluate.py`) - Script ƒë√°nh gi√° legacy

## 1. Comprehensive Model Testing

### Ch·ª©c nƒÉng

Test service (`test_model.py`) cung c **Metrics to√†n di·ªán:**

-   Overall: MAE, RMSE, MAPE, Coverage, Interval Width
-   Horizon-wise: Metrics theo t·ª´ng kho·∫£ng th·ªùi gian (24h, 7d, 14d)
-   Quantile Loss: Pinball loss cho t·ª´ng quantil  **Visualizations:**

-   Forecast samples v·ªõi uncertainty bands
-   Error distribution analysis
-   Coverage analysis by horizon
-   Interval width analys **Output files:**

-   `metrics.json` - Metrics d·∫°ng JSON
-   `metrics.txt` - Metrics d·∫°ng text d·ªÖ ƒë·ªçc
-   `forecast_samples.png` - Sample predictions
-   `error_analysis.png` - Error distribution plots
-   `coverage_analysis.png` - Coverage plots

### S·ª≠ d·ª•ng

```bash
# Test c∆° b·∫£n (s·ª≠ d·ª•ng best checkpoint t·ª´ config)
python -m src.water_forecast.test_model --cfg configs/default.yaml

# Test v·ªõi checkpoint c·ª• th·ªÉ
python -m src.water_forecast.test_model \
    --cfg configs/default.yaml \
    --ckpt models/tft-best.ckpt

# Ch·ªâ ƒë·ªãnh s·ªë l∆∞·ª£ng samples ƒë·ªÉ plot
python -m src.water_forecast.test_model \
    --cfg configs/default.yaml \
    --samples 10

# S·ª≠ d·ª•ng Makefile
make test-model
```

### Output

K·∫øt qu·∫£ ƒë∆∞·ª£c l∆∞u trong `artifacts/test_results/`:

```
artifacts/test_results/
‚îú‚îÄ‚îÄ metrics.json              # Metrics chi ti·∫øt
‚îú‚îÄ‚îÄ metrics.txt               # B√°o c√°o text
‚îú‚îÄ‚îÄ forecast_samples.png      # D·ª± ƒëo√°n m·∫´u
‚îú‚îÄ‚îÄ error_analysis.png        # Ph√¢n t√≠ch l·ªói
‚îî‚îÄ‚îÄ coverage_analysis.png     # Ph√¢n t√≠ch coverage
```

### V√≠ d·ª• output metrics

```
============================================================
üìä MODEL EVALUATION RESULTS
============================================================

üéØ Overall Performance:
  MAE                 :   0.1234
  RMSE                :   0.2456
  MAPE                :   5.6789
  Coverage_80%        :  78.9012
  Interval_Width      :   0.5678
  Sharpness           :   0.1234

‚è±Ô∏è  Horizon-wise Performance:
  MAE_24h             :   0.1111
  RMSE_24h            :   0.2222
  MAE_7d              :   0.1333
  RMSE_7d             :   0.2444
  MAE_14d             :   0.1456
  RMSE_14d            :   0.2567

üìâ Quantile Loss:
  Pinball_Q10         :   0.0123
  Pinball_Q50         :   0.0456
  Pinball_Q90         :   0.0789
  Avg_Pinball         :   0.0456
============================================================
```

## 2. Unit Tests

### C√°c test c√≥ s·∫µn

#### `tests/test_model.py`

Test c√°c ch·ª©c nƒÉng c·ªßa model:

- Model creation from dataset
- Forward pass
- Prediction generation
- Training step
- Save/load checkpoint
- Metrics calculation

#### `tests/test_ingest.py`

Test data ingestion:

- CSV reading
- Column validation
- Timestamp parsing
- Data cleaning

#### `tests/test_preprocessing.py`

Test preprocessing:

- Train/val/test split
- Scaling/normalization
- Feature engineering

### Ch·∫°y unit tests

```bash
# Ch·∫°y t·∫•t c·∫£ tests
pytest tests/ -v

# Ch·∫°y test c·ª• th·ªÉ
pytest tests/test_model.py -v
pytest tests/test_model.py::TestModelTraining::test_model_creation -v

# Ch·∫°y v·ªõi coverage
pytest tests/ --cov=src/water_forecast --cov-report=html

# Ch·∫°y parallel (nhanh h∆°n)
pytest tests/ -n auto

# S·ª≠ d·ª•ng Makefile
make test-unit
```

### V√≠ d·ª• output

```
tests/test_model.py::TestModelTraining::test_model_creation PASSED      [ 10%]
tests/test_model.py::TestModelTraining::test_model_forward_pass PASSED  [ 20%]
tests/test_model.py::TestModelTraining::test_model_prediction PASSED    [ 30%]
tests/test_model.py::TestModelTraining::test_model_training_step PASSED [ 40%]
tests/test_model.py::TestModelTraining::test_model_load_checkpoint PASSED [ 50%]
tests/test_model.py::TestModelMetrics::test_mae_calculation PASSED      [ 60%]
tests/test_model.py::TestModelMetrics::test_coverage_calculation PASSED [ 70%]
tests/test_model.py::TestModelMetrics::test_pinball_loss PASSED         [ 80%]

========================== 8 passed in 45.23s ===========================
```

## 3. Evaluation Script (Legacy)

Script evaluate.py c≈© v·∫´n c√≥ s·∫µn:

```bash
python -m src.water_forecast.evaluate --cfg configs/default.yaml
```

Output:

-   `artifacts/metrics.txt` - Metrics c∆° b·∫£n
-   `artifacts/forecast_0.png` - Sample forecasts

## 4. Workflow Testing Ho√†n ch·ªânh

### Development Workflow

```bash
# 1. Setup environment
python -m venv .venv
source .venv/bin/activate  # ho·∫∑c `.venv\Scripts\activate` tr√™n Windows
pip install -r requirements-dev.txt

# 2. Run unit tests during development
pytest tests/test_model.py -v --tb=short

# 3. Train model
python -m src.water_forecast.train --cfg configs/default.yaml

# 4. Comprehensive evaluation
python -m src.water_forecast.test_model --cfg configs/default.yaml

# 5. Review results
ls -la artifacts/test_results/
```

### CI/CD Workflow

```bash
# Run all tests
make test

# Ho·∫∑c
pytest tests/ -v && python -m src.water_forecast.test_model --cfg configs/default.yaml
```

## 5. Interpreting Results

### MAE & RMSE

-   **MAE**: L·ªói tuy·ªát ƒë·ªëi trung b√¨nh, ƒë∆°n v·ªã gi·ªëng v·ªõi target
-   **RMSE**: Nh·∫•n m·∫°nh l·ªói l·ªõn h∆°n, ƒë∆°n v·ªã gi·ªëng v·ªõi target
-   **Best**: C√†ng th·∫•p c√†ng t·ªët
-   **Typical**: MAE < RMSE (do RMSE penalize outliers)

### Coverage

-   **Target**: 80% (cho [Q10, Q90] interval)
-   **Good**: 75-85%
-   **Too narrow**: >85% ‚Üí Model qu√° t·ª± tin
-   **Too wide**: <75% ‚Üí Model kh√¥ng t·ª± tin

### Pinball Loss

-   **Lower is better**
-   **Q50** (median): Th∆∞·ªùng th·∫•p nh·∫•t
-   **Q10/Q90**: Th∆∞·ªùng cao h∆°n do extreme quantiles

### Horizon-wise Metrics

-   **Expected**: Error tƒÉng theo horizon (xa h∆°n ‚Üí kh√≥ ƒëo√°n h∆°n)
-   **Issue**: N·∫øu error tƒÉng ƒë·ªôt ng·ªôt ‚Üí c·∫ßn review model

## 6. Troubleshooting

### L·ªói th∆∞·ªùng g·∫∑p

#### 1. Import Error

```
ImportError: cannot import name 'seed_everything'
```

**Fix**: C√†i ƒë√∫ng version Lightning:

```bash
pip install 'lightning>=2.0,<3.0'
```

#### 2. Checkpoint not found

```
FileNotFoundError: Checkpoint not found
```

**Fix**: Ch·ªâ ƒë·ªãnh ƒë∆∞·ªùng d·∫´n checkpoint:

```bash
python -m src.water_forecast.test_model --ckpt models/tft-best.ckpt
```

#### 3. Out of memory

```
RuntimeError: CUDA out of memory
```

**Fix**: Gi·∫£m batch size trong config ho·∫∑c d√πng CPU:

```yaml
batch_size: 16 # gi·∫£m t·ª´ 32
```

#### 4. No test data

```
AssertionError: Test set is empty
```

**Fix**: Ki·ªÉm tra split ratio trong config:

```yaml
split:
    train_ratio: 0.7
    val_ratio: 0.15
    # test_ratio: 0.15 (t·ª± ƒë·ªông)
```

## 7. Best Practices

# DO

-   Ch·∫°y unit tests tr∆∞·ªõc khi training
-   Test v·ªõi nhi·ªÅu random seeds ƒë·ªÉ ki·ªÉm tra stability
-   L∆∞u metrics cho m·ªói experiment
-   So s√°nh metrics gi·ªØa c√°c versions
-   Review visualizations ƒë·ªÉ hi·ªÉu model behavior

### DON'T

-   Kh√¥ng test tr√™n training data
-   Kh√¥ng b·ªè qua warnings
-   Kh√¥ng ch·ªâ nh√¨n v√†o 1 metric duy nh·∫•t
-   Kh√¥ng ignore outliers trong error analysis

## 8. Advanced Testing

### A/B Testing

```bash
# Test model A
python -m src.water_forecast.test_model \
    --cfg configs/default.yaml \
    --ckpt models/model_a.ckpt

# Test model B
python -m src.water_forecast.test_model \
    --cfg configs/default.yaml \
    --ckpt models/model_b.ckpt

# Compare results
diff artifacts/test_results_a/metrics.json artifacts/test_results_b/metrics.json
```

### Statistical Significance Testing

Th√™m v√†o test script (t√πy ch·ªçn):

```python
from scipy import stats

# Compare predictions from 2 models
errors_a = actuals - preds_a
errors_b = actuals - preds_b

# Paired t-test
t_stat, p_value = stats.ttest_rel(np.abs(errors_a), np.abs(errors_b))

if p_value < 0.05:
    print("Difference is statistically significant!")
```

## 9. Continuous Integration Example

`.github/workflows/test.yml`:

```yaml
name: Test

on: [push, pull_request]

jobs:
    test:
        runs-on: ubuntu-latest
        steps:
            - uses: actions/checkout@v2
            - uses: actions/setup-python@v2
              with:
                  python-version: '3.11'
            - name: Install dependencies
              run: pip install -r requirements-dev.txt
            - name: Run unit tests
              run: pytest tests/ -v --cov=src
            - name: Upload coverage
              uses: codecov/codecov-action@v2
```

## 10. T√†i li·ªáu tham kh·∫£o

-   [PyTest Documentation](https://docs.pytest.org/)
-   [PyTorch Lightning Testing](https://lightning.ai/docs/pytorch/stable/common/evaluation.html)
-   [Model Evaluation Best Practices](https://scikit-learn.org/stable/modules/model_evaluation.html)

---

**C√¢u h·ªèi?** M·ªü issue tr√™n GitHub ho·∫∑c li√™n h·ªá team.
